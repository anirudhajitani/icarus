diff --git a/examples/offpath-vs-onpath-caching/config.py b/examples/offpath-vs-onpath-caching/config.py
index 058d1d6..e420232 100644
--- a/examples/offpath-vs-onpath-caching/config.py
+++ b/examples/offpath-vs-onpath-caching/config.py
@@ -54,7 +54,8 @@ ALPHA = [0.6, 0.8, 1.0, 1.2]
 NETWORK_CACHE = [0.004, 0.002, 0.01, 0.05]
 
 # Number of content objects
-N_CONTENTS = 3 * 10 ** 5
+#N_CONTENTS = 3 * 10 ** 5
+N_CONTENTS = 10 ** 3
 
 # Number of requests per second (over the whole network)
 NETWORK_REQUEST_RATE = 12.0
@@ -118,8 +119,10 @@ for alpha in ALPHA:
             for network_cache in NETWORK_CACHE:
                 experiment = copy.deepcopy(default)
                 experiment['workload']['alpha'] = alpha
-                experiment['strategy']['name'] = strategy
+                #experiment['strategy']['name'] = strategy
+                experiment['strategy']['name'] = 'ON_PATH_EDGE' 
                 experiment['topology']['name'] = topology
+                #experiment['topology']['name'] = 'WIDE'
                 experiment['cache_placement']['network_cache'] = network_cache
                 experiment['desc'] = "Alpha: %s, strategy: %s, topology: %s, network cache: %s" \
                                      % (str(alpha), strategy, topology, str(network_cache))
diff --git a/examples/offpath-vs-onpath-caching/res b/examples/offpath-vs-onpath-caching/res
new file mode 100644
index 0000000..8b13789
--- /dev/null
+++ b/examples/offpath-vs-onpath-caching/res
@@ -0,0 +1 @@
+
diff --git a/examples/single-experiment-line-topology/config.py b/examples/single-experiment-line-topology/config.py
index 6c64317..6896ef8 100644
--- a/examples/single-experiment-line-topology/config.py
+++ b/examples/single-experiment-line-topology/config.py
@@ -42,13 +42,13 @@ experiment = Tree()
 
 # Set topology
 experiment['topology']['name'] = 'PATH'
-experiment['topology']['n'] = 10
+experiment['topology']['n'] = 4
 experiment['topology']['delay'] = 10
 
 # Set workload
 experiment['workload'] = {
          'name':       'STATIONARY',
-         'n_contents': 10 ** 5,
+         'n_contents': 5,
          'n_warmup':   10 ** 2,
          'n_measured': 4 * 10 ** 2,
          'alpha':      1.0,
@@ -66,7 +66,7 @@ experiment['content_placement']['name'] = 'UNIFORM'
 experiment['cache_policy']['name'] = 'LRU'
 
 # Set caching meta-policy
-experiment['strategy']['name'] = 'LCE'
+experiment['strategy']['name'] = 'ON_PATH_EDGE'
 
 # Description of the experiment
 experiment['desc'] = "Line topology with 10 nodes"
diff --git a/icarus/execution/collectors.py b/icarus/execution/collectors.py
index caa2d09..22e94fc 100644
--- a/icarus/execution/collectors.py
+++ b/icarus/execution/collectors.py
@@ -327,13 +327,16 @@ class LatencyCollector(DataCollector):
     @inheritdoc(DataCollector)
     def end_session(self, success=True):
         if not success:
+            print ("LATENCY COLLECTOR NOT SUCCESS")
             return
         if self.cdf:
             self.latency_data.append(self.sess_latency)
         self.latency += self.sess_latency
+        print ("GOOD TILL HERE____1")
 
     @inheritdoc(DataCollector)
     def results(self):
+        print ("COLLECTOR RESULTS")
         results = Tree({'MEAN': self.latency / self.sess_count})
         if self.cdf:
             results['CDF'] = cdf(self.latency_data)
@@ -406,7 +409,9 @@ class CacheHitRatioCollector(DataCollector):
 
     @inheritdoc(DataCollector)
     def results(self):
+        print ("GOOD IN RESULTS CACHE_HIT")
         n_sess = self.cache_hits + self.serv_hits
+        print ("N_SESS", n_sess)
         hit_ratio = self.cache_hits / n_sess
         results = Tree(**{'MEAN': hit_ratio})
         if self.off_path_hits:
@@ -427,6 +432,7 @@ class CacheHitRatioCollector(DataCollector):
                 self.per_node_server_hits[v] /= n_sess
             results['PER_NODE_CACHE_HIT_RATIO'] = self.per_node_cache_hits
             results['PER_NODE_SERVER_HIT_RATIO'] = self.per_node_server_hits
+        print ("GOOD IN RESULTS CACHE_HIT END")
         return results
 
 
diff --git a/icarus/execution/engine.py b/icarus/execution/engine.py
index f2c657c..e005b9f 100644
--- a/icarus/execution/engine.py
+++ b/icarus/execution/engine.py
@@ -55,7 +55,13 @@ def exec_experiment(topology, workload, netconf, strategy, cache_policy, collect
     strategy_name = strategy['name']
     strategy_args = {k: v for k, v in strategy.items() if k != 'name'}
     strategy_inst = STRATEGY[strategy_name](view, controller, **strategy_args)
-
+    i = 0
+    for time, event in workload:
+        print("ITER______", i)
+        i += 1
+    i = 0
     for time, event in workload:
         strategy_inst.process_event(time, **event)
+        print("ITER_884848484_____", i)
+        i += 1
     return collector.results()
diff --git a/icarus/execution/network.py b/icarus/execution/network.py
index 5428ab5..1d361b1 100644
--- a/icarus/execution/network.py
+++ b/icarus/execution/network.py
@@ -16,6 +16,9 @@ import logging
 
 import networkx as nx
 import fnss
+import numpy as np
+import math
+import sys
 
 from icarus.registry import CACHE_POLICY
 from icarus.util import iround, path_links
@@ -76,6 +79,79 @@ class NetworkView(object):
             raise ValueError('The model argument must be an instance of '
                              'NetworkModel')
         self.model = model
+        self.count = 0
+        self.first = True
+        print ("NW VIEW INIT")
+
+    def get_state(self):
+        for r in self.model.routers :
+            contents = self.cache_dump(r)
+            print ("R C", r, contents)
+            for c in contents :
+                self.model.state[self.model.routers.index(r), c-1] = 1.0
+                print ("val ", self.model.state[self.model.routers.index(r), c-1])
+        #add popularity
+        self.calculate_popularity()
+        print ("STATE ::: ", self.model.state)
+        print ("POPS ", self.model.popularity)
+        self.current_state = np.concatenate((self.model.state, self.model.popularity), axis=1)
+        return self.current_state
+
+    def calculate_popularity(self):
+            self.model.popularity /= 100.0
+
+    
+    def encode_state(self):
+        expo = 0
+        encoding_2 = 0
+        state_matrix = get_state()
+        for x in xrange(state_matrix.shape[0]/2):
+            for y in xrange(state_matrix.shape[1]):
+                encoding_2 += state_matrix[x, y] * (2 ** expo)
+                expo += 1
+        encoding = encoding_2 * (3 ** (state_matrix.shape[0]/2 * state_matrix.shape[1]))
+        expo = 0
+        encoding_3 = 0
+        for x in range(state_matrix.shape[0]/2, state_matrix.shape[0]):
+            for y in xrange(state_matrix.shape[1]):
+                encoding_3 += math.floor(state_matrix[x,y] * 3) * (3 ** expo)    
+                expo += 1
+        encoding += encoding_3
+        return encoding
+
+    def encode_action(self, action_matrix):
+        expo = 0
+        encoding = 0
+        for (x,y), value in np.ndenumerate(action_matrix):
+             encoding += value * (2 ** expo)
+             expo += 1
+        return encoding
+
+    """
+    def decode_state(self, encoding):
+        state_matrix = np.full((len(self.model.routers), 2 * len(self.model.library)), 0, dtype=int)
+    """
+
+    def decode_action(self, encoding):
+        action_matrix = np.full((len(self.model.routers), len(self.model.library)), 0, dtype=int)
+        for x in range(action_matrix.shape[0]):
+            for y in range(action_matrix.shape[1]):
+                action_matrix[x,y] = encoding % 2
+                encoding = encoding // 2
+        return action_matrix
+
+    def get_action(self):
+        state = encode_state()
+        action = decode_action(np.argmax(self.q_table[state, :]))
+        self.current_action = action
+        return self.current_action
+        #take action and get rewards
+        #next state computed by current action and popularity matrix as it is as previous state
+
+    def update_q_table(self, rewards, alpha, gamma): 
+        old_state = self.current_state
+        next_state = encode_state()
+        self.model.q_table[(old_state, self.current_action)] = (1.0 - alpha) * self.model.q_table[(old_state, self.current_action)] + alpha * ((rewards + gamma * np.max(self.model.q_table[next_state,:]) - self.model.q_table[old_state, self.current_action]))
 
     def content_locations(self, k):
         """Return a set of all current locations of a specific content.
@@ -355,9 +431,10 @@ class NetworkModel(object):
         # Dictionary mapping each content object to its source
         # dict of location of contents keyed by content ID
         self.content_source = {}
+        self.library = set()
         # Dictionary mapping the reverse, i.e. nodes to set of contents stored
         self.source_node = {}
-
+        self.routers = []
         # Dictionary of link types (internal/external)
         self.link_type = nx.get_edge_attributes(topology, 'type')
         self.link_delay = fnss.get_delays(topology)
@@ -377,10 +454,12 @@ class NetworkModel(object):
             if stack_name == 'router':
                 if 'cache_size' in stack_props:
                     cache_size[node] = stack_props['cache_size']
+                    self.routers.append(node)
             elif stack_name == 'source':
                 contents = stack_props['contents']
                 self.source_node[node] = contents
                 for content in contents:
+                    self.library.add(content)
                     self.content_source[content] = node
         if any(c < 1 for c in cache_size.values()):
             logger.warn('Some content caches have size equal to 0. '
@@ -388,7 +467,22 @@ class NetworkModel(object):
             for node in cache_size:
                 if cache_size[node] < 1:
                     cache_size[node] = 1
-
+        print ("CACHES", self.routers)
+        print ("LIBRARY LEN", len(self.library))
+        self.rewards = 0
+        self.state = np.full((len(self.routers), len(self.library)), 0.0, dtype=float)
+        self.actions = np.full((len(self.routers), len(self.library)), 0, dtype=int)
+        self.popularity = np.full((len(self.routers), len(self.library)), 0.0, dtype=float)
+        print ("FIne before q-table")
+        dimension_1 = (2 ** (len(self.routers) * len(self.library))) * (3 ** (len(self.routers) * len(self.library)))
+        dimension_2 = (2 ** (len(self.routers) * len(self.library)))
+        print ("DImensions", dimension_1, dimension_2)
+        try :
+            self.q_table = np.full((dimension_1, dimension_2), 0.0, dtype=float)
+        except :
+            print ("Error: ", sys.exc_info()[0])
+            exit()
+        print ("INIT OF RL COMP DONE")
         policy_name = cache_policy['name']
         policy_args = {k: v for k, v in cache_policy.items() if k != 'name'}
         # The actual cache objects storing the content
@@ -547,7 +641,7 @@ class NetworkController(object):
         if self.collector is not None and self.session['log']:
             self.collector.content_hop(u, v, main_path)
 
-    def put_content(self, node):
+    def put_content(self, node, content=None):
         """Store content in the specified node.
 
         The node must have a cache stack and the actual insertion of the
@@ -565,10 +659,12 @@ class NetworkController(object):
         evicted : any hashable type
             The evicted object or *None* if no contents were evicted.
         """
-        if node in self.model.cache:
+        if node in self.model.cache and content is None:
             return self.model.cache[node].put(self.session['content'])
+        if node in self.model.cache and content is not None:
+            return self.model.cache[node].put(content)
 
-    def get_content(self, node):
+    def get_content(self, node, content=None):
         """Get a content from a server or a cache.
 
         Parameters
@@ -581,6 +677,8 @@ class NetworkController(object):
         content : bool
             True if the content is available, False otherwise
         """
+        if node in self.model.cache and content is not None:
+            return self.model.cache[node].get(content)
         if node in self.model.cache:
             cache_hit = self.model.cache[node].get(self.session['content'])
             if cache_hit:
diff --git a/icarus/models/strategy/onpath.py b/icarus/models/strategy/onpath.py
index b76d21f..194f1eb 100644
--- a/icarus/models/strategy/onpath.py
+++ b/icarus/models/strategy/onpath.py
@@ -11,6 +11,7 @@ from .base import Strategy
 
 __all__ = [
        'Partition',
+       'OnPathEdge',
        'Edge',
        'LeaveCopyEverywhere',
        'LeaveCopyDown',
@@ -64,6 +65,101 @@ class Partition(Strategy):
         self.controller.end_session()
 
 
+@register_strategy('ON_PATH_EDGE')
+class OnPathEdge(Strategy):
+    """Edge caching strategy.
+    MAKE SURE CACHING POLICY IS LRU
+    In this strategy only a cache at the edge is looked up before forwarding
+    a content request to the original source.
+
+    In practice, this is like an LCE but it only queries the cache it
+    finds in the path. It is assumed to be used with a topology where each
+    PoP has a cache but it simulates a case where the cache is actually further
+    down the access network and it is not looked up for transit traffic passing
+    through the PoP but only for PoP-originated requests.
+    """
+
+    @inheritdoc(Strategy)
+    def __init__(self, view, controller):
+        super(OnPathEdge, self).__init__(view, controller)
+
+    @inheritdoc(Strategy)
+    def process_event(self, time, receiver, content, log):
+        # get all required data
+        print ("SESSION BEGIN")
+        print ("Process Event ", time, receiver, content)
+        source = self.view.content_source(content)
+        self.controller.start_session(time, receiver, content, log)
+        self.view.count = (self.view.count + 1) % 100
+        if self.view.count == 0 :
+            try:
+                if not self.view.first :
+                    self.view.update_q_table(self.view.model.rewards, 0.1, 0.9)
+                else :
+                    self.view.first = False
+                self.view.model.rewards = 0
+                #get state and action
+                action = get_action()
+                #cache the relevant contents (for now assume LRU eviction policy)
+                #In case of more contents to be cached then allowed, it will use LRU to evict the first contents
+                for (x,y), value in np.ndenumerate(action):
+                    if value == 1:
+                        if not self.controller.get_content(self.view.model.routers[x],y):
+                            self.controller.put_content(self.view.model.routers[x],y)
+                            #negative reward for cache eviction and swapping
+                            rewards -= 1
+                #perform the caching
+                #reset the popularity of the contents 
+                self.view.model.popularity *= 0
+                #self.view.get_state()
+            except:
+                print ("EROOR HEREEEEEEE")
+        content_loc = self.view.content_locations(content)
+        print ("Locations of content", content_loc)
+        min_delay_path = 1000000
+        min_path = []
+        for c in content_loc :
+            path = self.view.shortest_path(receiver, c)
+            print ("Path from rx to content location", path)
+            #print ("State : ", self.view.get_state())
+            # Route requests to original source and queries caches on the path
+            current_delay = 0
+            print ("Path Links", path_links(path))
+            for u, v in path_links(path):
+                print ("Link Delay", u, v, self.view.link_delay(u, v))
+                current_delay = current_delay + self.view.link_delay(u,v)
+                self.controller.forward_request_hop(u, v)
+                #print ("Cache dump of ", v , "is: ", self.view.cache_dump(v))
+            if current_delay < min_delay_path:
+                min_delay_path = current_delay
+                min_path = path
+                serving_node = c
+        print ("Min Path : ", min_path)
+        for u, v in path_links(min_path):
+            self.controller.forward_request_hop(u, v)
+            if self.view.has_cache(v) and v != source:
+                print (v, " has cache")
+                print ("Routers :", self.view.model.routers) 
+                try:
+                    print ("Inx", self.view.model.routers.index(v))
+                    print ("val", self.view.model.popularity[self.view.model.routers.index(v), content-1])
+                    self.view.model.popularity[self.view.model.routers.index(v), content-1] += 1.0
+                    print ("val after", self.view.model.popularity[self.view.model.routers.index(v), content-1])
+                except:
+                    print ("ERROR HERE", v)
+        # No caches on the path at all, get it from source
+        print ("Serving Node : ", c)
+        print ("Total Delay : ", min_delay_path)
+        self.view.model.rewards -= min_delay_path
+        self.controller.get_content(c)
+        # Return content
+        path = list(reversed(self.view.shortest_path(receiver, serving_node)))
+        self.controller.forward_content_path(serving_node, receiver, path)
+        #if serving_node == source:
+        #    self.controller.put_content(edge_cache)
+        self.controller.end_session()
+        print ("SESSION END")
+
 @register_strategy('EDGE')
 class Edge(Strategy):
     """Edge caching strategy.
diff --git a/icarus/scenarios/contentplacement.py b/icarus/scenarios/contentplacement.py
index 585b0d3..56b169f 100644
--- a/icarus/scenarios/contentplacement.py
+++ b/icarus/scenarios/contentplacement.py
@@ -60,6 +60,7 @@ def uniform_content_placement(topology, contents, seed=None):
     content_placement = collections.defaultdict(set)
     for c in contents:
         content_placement[random.choice(source_nodes)].add(c)
+    #print ("CONTENT PLAC ", content_placement)
     apply_content_placement(content_placement, topology)
 
 
diff --git a/icarus/scenarios/workload.py b/icarus/scenarios/workload.py
index 02b9ffd..eabdaeb 100644
--- a/icarus/scenarios/workload.py
+++ b/icarus/scenarios/workload.py
@@ -90,7 +90,15 @@ class StationaryWorkload(object):
             raise ValueError('beta must be positive')
         self.receivers = [v for v in topology.nodes()
                      if topology.node[v]['stack'][0] == 'receiver']
+        print ("RX : ", self.receivers)
+        self.sources = [v for v in topology.nodes()
+                     if topology.node[v]['stack'][0] == 'source']
+        print ("SOURCE : ", self.sources)
+        self.routers = [v for v in topology.nodes()
+                     if topology.node[v]['stack'][0] == 'router']
+        print ("ROUTERS : ", self.routers)
         self.zipf = TruncatedZipfDist(alpha, n_contents)
+        #print ("ZIPF : ", self.zipf)
         self.n_contents = n_contents
         self.contents = range(1, n_contents + 1)
         self.alpha = alpha
@@ -116,6 +124,7 @@ class StationaryWorkload(object):
             content = int(self.zipf.rv())
             log = (req_counter >= self.n_warmup)
             event = {'receiver': receiver, 'content': content, 'log': log}
+            print ("EVENT : ", event)
             yield (t_event, event)
             req_counter += 1
         raise StopIteration()
